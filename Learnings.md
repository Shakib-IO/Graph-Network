# Graph Neural Network

#### Gradient Descent
* Architectures such as GCN and ChebNet, MoNet and GAT were trained using full-batch gradient descent, which holds the entire graph adjacency matrix and node features in memory.
<img width="1086" alt="Screenshot 2024-01-09 at 12 51 04â€¯PM" src="https://github.com/Shakib-IO/Graph-Network/assets/65369990/e0db1cc9-6538-4562-9c76-ca0098fa6206"> <br>
* [First-Order Optimization Algorithms for Machine Learning](https://www.cs.ubc.ca/~schmidtm/Courses/5XX-S20/)
